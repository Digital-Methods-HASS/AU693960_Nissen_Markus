---
title: "Game of Thrones sentiment analysis"
author: "Markus"
date: "2022-12-02, last edited  "
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)

library(pdftools)
library(tidytext)
library(textdata) 
library(ggwordcloud)
```


First step is to read the got.pdf as a pdf-file.
```{r}
got_path <- here("data","got.pdf")
got_text <- pdf_text(got_path)

```


Then the read file is turned into a dataframe.

```{r}
got_df <- data.frame(got_text) %>% 
  mutate(text_full = str_split(got_text, pattern = '\\n')) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full))

```


Now we tokenize the data to get indivdual words in the tidy format.
```{r}
got_tokens <- got_df %>% 
  unnest_tokens(word, text_full)

```

Now we count the words

```{r}
got_wc <- got_tokens %>% 
  count(word) %>% 
  arrange(-n)
got_wc

```



```{r}
got_stop <- got_tokens %>% 
  anti_join(stop_words) %>% 
  select(-got_text)

```

Now we check the word count again.

```{r}
got_swc <- got_stop %>% 
  count(word) %>% 
  arrange(-n)

```

Now we filter out all numbers

```{r}
got_no_numeric <- got_stop %>% 
  filter(is.na(as.numeric(word)))

```



Now we prepare a wordcloud.
```{r}
length(unique(got_no_numeric$word))

#We only want the top 100 words

got_top100 <- got_no_numeric %>% 
  count(word) %>% 
  arrange(-n) %>% 
  head(100)

```

Now we create a wordcloud
```{r}
got_cloud <- ggplot(data = got_top100, aes(label = word)) +
  geom_text_wordcloud() +
  theme_minimal()

got_cloud
```

Now we customize so that the most frequent words are biggest, and the least frequent are the smallest.

```{r}
ggplot(data = got_top100, aes(label = word, size = n)) +
  geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
  scale_size_area(max_size = 12) +
  scale_color_gradientn(colors = c("darkgreen","blue","red")) +
  theme_minimal()

```


Now for the actual sentiment analysis

First download afinn, bing, and nrc
```{r}
get_sentiments(lexicon = "afinn")

get_sentiments(lexicon = "bing")

get_sentiments(lexicon = "nrc")
```


## Sentiment analysis using afinn:
first we bind the words from got_stop to afinn
```{r}
got_afinn <- got_stop %>% 
  inner_join(get_sentiments("afinn"))
```

Now we find the sentiment rankings and plot them

```{r}
got_afinn_hist <- got_afinn %>% 
  count(value)

ggplot(data = got_afinn_hist, aes(x = value, y = n)) +
  geom_col()

```

Now we investigate som of our results
```{r}
got_afinn_minus_5 <- got_afinn %>% 
  filter(value == -5)

got_afinn_minus_5
```

```{r}
unique(got_afinn_minus_5$word)

got_afinn_minus_5_n <- got_afinn_minus_5 %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(factor(word), n))


ggplot(data = got_afinn_minus_5_n, aes(x = word, y = n)) +
  geom_col() +
  coord_flip()
```


Now we can summarize the sentiment score for Game of Thrones

```{r}
got_summary <- got_afinn %>% 
  summarize(
    mean_score = mean(value),
    median_score = median(value)
  )

got_summary

```

#NRC analysis

Now we start "binning" the words to the feeling, with which they are often associated. 

```{r}
got_nrc <- got_stop %>% 
  inner_join(get_sentiments("nrc"))

```

Before we do the actual analysis, it is imperative that we know which words are excluded by default, and we will check this now. Additionally, we will also see what word is the most excluded.

```{r}
got_exclude <- got_stop %>% 
  anti_join(get_sentiments("nrc"))

View(got_exclude)

# Finding the most excluded word
got_exclude_n <- got_exclude %>% 
  count(word, sort = TRUE)

head(got_exclude_n)
```


Now for the actual analysis 

We first find the counts for the sentiment-count, that each word is associated with and then we plot it.

```{r}
got_nrc_n <- got_nrc %>% 
  count(sentiment, sort = TRUE)

# And plot them:

ggplot(data = got_nrc_n, aes(x = sentiment, y = n)) +
  geom_col()
```

Now we count for sentiment and word, then facet it.

```{r}
got_nrc_n5 <- got_nrc %>% 
  count(word,sentiment, sort = TRUE) %>% 
  group_by(sentiment) %>% 
  top_n(5) %>% 
  ungroup()

got_nrc_gg <- ggplot(data = got_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, ncol = 2, scales = "free") +
  coord_flip() +
  theme_minimal() +
  labs(x = "Word", y = "count")

got_nrc_gg
```


```{r, include=FALSE}
# for saving the plot
ggsave(plot = got_nrc_gg, 
       here("figures","got_nrc_sentiment.png"), 
       height = 8, 
       width = 5)
```





